import asyncio
import aiohttp
import time
import sys
from datetime import datetime, timedelta, timezone
import logging
import json

# ì„¤ì • ë° í¬ë¡¤ëŸ¬, ì„œë¹„ìŠ¤ ëª¨ë“ˆ ì„í¬íŠ¸
import config
from crawlers.rss import process_rss_feed
from crawlers.mk_opinion import process_mk_opinion
from crawlers.thebell import get_thebell_news_async
from services.gemini import summarize_text
from services.telegram import send_telegram_message
from utils.helpers import load_sent_articles, save_sent_articles

# Trafilatura ë¡œê¹… ë„ê¸°
logging.getLogger('trafilatura').setLevel(logging.CRITICAL)

async def main():
    start_time = time.time()
    
    now_utc = datetime.now(timezone.utc)
    now_kst = datetime.now(config.KST)
    
    check_time_utc = now_utc - timedelta(hours=config.TIME_LIMIT_HOURS)
    check_time_kst = now_kst - timedelta(hours=config.TIME_LIMIT_HOURS)

    print(f"ğŸš€ [{now_kst.strftime('%Y-%m-%d %H:%M:%S')}] ì „ì²´ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘ (ìµœê·¼ {config.TIME_LIMIT_HOURS}ì‹œê°„)\n")

    async with aiohttp.ClientSession() as session:
        tasks = []
        
        # RSS í”¼ë“œ íƒœìŠ¤í¬ ì¶”ê°€
        for feed in config.RSS_FEEDS:
            tasks.append(process_rss_feed(session, feed, check_time_utc))
            
        # ë§¤ê²½ ì˜¤í”¼ë‹ˆì–¸ íƒœìŠ¤í¬ ì¶”ê°€
        tasks.append(process_mk_opinion(session, check_time_kst))
        
        # ë”ë²¨ íƒœìŠ¤í¬ ì¶”ê°€
        tasks.append(get_thebell_news_async(session, check_time_kst))

        all_results_grouped = await asyncio.gather(*tasks)

    flat_news_list = [news for group in all_results_grouped for news in group]

    # ìˆ˜ì§‘ëœ ê¸°ì‚¬ ëª©ë¡ ë‚´ì—ì„œ ë§í¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±°
    print(f"\n- ì¤‘ë³µ ì œê±° ì „ ê¸°ì‚¬ ìˆ˜: {len(flat_news_list)}")
    unique_articles = {}
    for article in flat_news_list:
        link = article.get('link')
        if link and link not in unique_articles:
            unique_articles[link] = article
    flat_news_list = list(unique_articles.values())
    print(f"- ì¤‘ë³µ ì œê±° í›„ ê¸°ì‚¬ ìˆ˜: {len(flat_news_list)}")
    
    flat_news_list.sort(key=lambda x: x['published_at'], reverse=True)

    end_time = time.time()
    
    print(f"\nâœ… [Complete] ëª¨ë“  ìˆ˜ì§‘ ì™„ë£Œ")
    print(f"ğŸ“Š ì´ {len(flat_news_list)}ê°œì˜ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤. (ì†Œìš”ì‹œê°„: {end_time - start_time:.2f}ì´ˆ)")
    print(f"{'='*60}\n")

    return flat_news_list

if __name__ == "__main__":
    # ìœˆë„ìš° í™˜ê²½ asyncio ì •ì±… ì„¤ì •
    if sys.platform == 'win32':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

    # Jupyter/Colab í™˜ê²½ ëŒ€ì‘
    if 'ipykernel' in sys.modules or 'google.colab' in sys.modules:
        try:
            import nest_asyncio
            nest_asyncio.apply()
            articles = asyncio.run(main())
        except ImportError:
            loop = asyncio.get_event_loop()
            articles = loop.run_until_complete(main())
    else:
        articles = asyncio.run(main())

    # ì „ì†¡ëœ ê¸°ì‚¬ ëª©ë¡ ë¡œë“œ (ë§í¬ë§Œ í¬í•¨ëœ set)
    sent_articles_file = "sent_articles.json"
    sent_links = load_sent_articles(sent_articles_file)

    # ìƒˆë¡œìš´ ê¸°ì‚¬ë§Œ í•„í„°ë§
    new_articles = [article for article in articles if article.get('link') not in sent_links]

    print(f"ì´ {len(articles)}ê°œì˜ ê¸°ì‚¬ ì¤‘ {len(new_articles)}ê°œì˜ ìƒˆë¡œìš´ ê¸°ì‚¬ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

    if not new_articles:
        print("ìƒˆë¡œìš´ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # ì „ì†¡ëœ ê¸°ì‚¬ ì •ë³´ë¥¼ ë‹´ì„ ë”•ì…”ë„ˆë¦¬ (ê¸°ì¡´ ë°ì´í„° ë¡œë“œ)
        try:
            with open(sent_articles_file, 'r', encoding='utf-8') as f:
                sent_articles_with_time = json.load(f)
        except (FileNotFoundError, json.JSONDecodeError):
            sent_articles_with_time = {}

        for article in new_articles:
            title = article.get('title', 'ì œëª© ì—†ìŒ')
            link = article.get('link', '')
            content = article.get('full_content', '')
            
            if not content:
                continue
            
            raw_date = article.get('published_at')
            date_str = ""
            
            if isinstance(raw_date, datetime):
                date_str = raw_date.strftime('%Yë…„ %mì›” %dì¼ %H:%M')
            else:
                date_str = str(raw_date) if raw_date else ""

            print(f"'{title}' ìš”ì•½ ì¤‘...")
            summary = summarize_text(content)

            message = f"[{article['source']}] {title}\n"
            if date_str:
                message += f"ğŸ“… {date_str}\n\n"
            else:
                message += "\n"
                
            message += f"{summary}\n\n"
            message += f"{link}"
            
            send_telegram_message(config.TELEGRAM_BOT_TOKEN, config.TELEGRAM_CHAT_ID, message)
            
            # ì „ì†¡ëœ ë§í¬ì™€ ì‹œê°„ ì¶”ê°€
            sent_articles_with_time[link] = datetime.now(timezone.utc).isoformat()

        # ì „ì†¡ëœ ê¸°ì‚¬ ëª©ë¡ ì €ì¥
        save_sent_articles(sent_articles_file, sent_articles_with_time)

    print("ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
